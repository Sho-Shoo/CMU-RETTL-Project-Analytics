{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# python setup \n",
    "import pandas as pd \n",
    "import time\n",
    "import numpy as np \n",
    "from datetime import datetime, timezone, timedelta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction \n",
    "In this notebool, we are going to develop some analytic tool to extract summary information from the tutor log data. There will also be code chunks distilling event-actor-subject data from the tutor log. \n",
    "\n",
    "The analytics tools will include: \n",
    "- Summary of student performance, i.e., percentage of correct attempts, etc.. \n",
    "- Average number of hints \n",
    "- Time taken to solve (mean, std) \n",
    "- Total number of problems solved \n",
    "- Total KC level performance \n",
    "- Struggle summary stats with data from LearnSphere Critical Struggle detector "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary Functions \n",
    "Below are functions that generates summary statistics mentioned above. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def EDTDatetime2epoch(dateTime, format=\"%Y-%m-%d %H:%M:%S\"):\n",
    "    \"\"\"Converts EDT date-time string to epoch time represented by an interger \n",
    "\n",
    "    Args:\n",
    "        datetime (str): date-time string, in EDT time zone\n",
    "        format (str, optional): python time module time string formats, read more in `time` documentation. Defaults to \"%Y-%m-%d %H:%M:%S\".\n",
    "\n",
    "    Returns: \n",
    "        int: epoch/unix time stamp integer\n",
    "    \"\"\"    \n",
    "\n",
    "    # read-in datetime string\n",
    "    datetimeStruct = datetime.strptime(dateTime, format) \n",
    "    # add time zone informartion \n",
    "    datetimeStruct = datetimeStruct.replace(tzinfo=timezone(timedelta(hours=-4))) \n",
    "    timestamp = datetimeStruct.timestamp()\n",
    "    return timestamp \n",
    "\n",
    "def UTCDatetime2epoch(dateTime, format=\"%Y-%m-%d %H:%M:%S\"):\n",
    "    \"\"\"Converts UTC date-time string to epoch time represented by an interger \n",
    "\n",
    "    Args:\n",
    "        datetime (str): date-time string, in UTC time zone\n",
    "        format (str, optional): python time module time string formats, read more in `time` documentation. Defaults to \"%Y-%m-%d %H:%M:%S\".\n",
    "\n",
    "    Returns: \n",
    "        int: epoch/unix time stamp integer\n",
    "    \"\"\"    \n",
    "\n",
    "    # read-in datetime string\n",
    "    datetimeStruct = datetime.strptime(dateTime, format) \n",
    "    # add time zone informartion \n",
    "    datetimeStruct = datetimeStruct.replace(tzinfo=timezone.utc) \n",
    "    timestamp = datetimeStruct.timestamp()\n",
    "    return timestamp \n",
    "\n",
    "def epoch2datetimeInEDT(timestamp):\n",
    "    \"\"\"Converts epoch time stamp to date-time string in EDT time zone \n",
    "\n",
    "    Args:\n",
    "        timestamp (int or float): epoch time stamp \n",
    "\n",
    "    Returns:\n",
    "        string: date-time string in EDT time zone\n",
    "    \"\"\"    \n",
    "\n",
    "    assert(timestamp >= 0)\n",
    "\n",
    "    dateTime = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return dateTime \n",
    "\n",
    "def filterWithStudents(tutorLogDF, students): \n",
    "    \"\"\"filter tutor log dataframe by students' anon user ids and return a filtered dataset \n",
    "\n",
    "    Args:\n",
    "        tutorLogDF (pd.DataFrame): tutor log data set \n",
    "        students (None or Iterable): an iterable with desired student anon ids \n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: a filtered dataset with just these wanted students \n",
    "    \"\"\"    \n",
    "    assert(students == None or len(students) > 0) # input check \n",
    "\n",
    "    filteredDF = tutorLogDF.copy()\n",
    "    if(students != None): filteredDF = tutorLogDF.loc[tutorLogDF[\"Anon Student Id\"].isin(students)] \n",
    "\n",
    "    return filteredDF\n",
    "\n",
    "def filterWithTime(tutorLogDF, startTime, endTime):\n",
    "    \"\"\"filter tutor log data by start and end time stamp. Usually used to extract data from a period \n",
    "\n",
    "    Args:\n",
    "        tutorLogDF (pd.DataFrame): tutor log data set \n",
    "        startTime (int): start time stamp\n",
    "        endTime (int): end time stamp\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: filtered dataset with entries from the time stamp interval \n",
    "    \"\"\"    \n",
    "    \n",
    "    assert(startTime == None or endTime == None or endTime > startTime) # input check \n",
    "\n",
    "    # filteredDF = tutorLogDF.copy()\n",
    "    # if(startTime != None): filteredDF = filteredDF.loc[filteredDF[\"timestamp\"] >= startTime]\n",
    "    # if(endTime != None): filteredDF = filteredDF.loc[filteredDF[\"timestamp\"] <= endTime] \n",
    "    \n",
    "    filteredDF = tutorLogDF.copy()\n",
    "    if(startTime != None): filteredDF = tutorLogDF.loc[tutorLogDF[\"timestamp\"] >= startTime]\n",
    "    if(endTime != None): filteredDF = filteredDF.loc[filteredDF[\"timestamp\"] <= endTime] \n",
    "\n",
    "    return filteredDF\n",
    "\n",
    "def getStudentPerformanceSummary(tutorLogDF, students=None, startTime=None, endTime=None):\n",
    "    \"\"\"\n",
    "    Measures student performance by percentage of attempt correctness during a time interval\n",
    "\n",
    "    Args:\n",
    "        tutorLogDF (pd.Dataframe): tutor log dataframe imported from a datashop exported file \n",
    "        students (Iterable): one/several anon_stud_id's to get the performance percentage \n",
    "        startTime (_int_): unix time stamp indicating the start of the interval \n",
    "        endTime (_int_): unix time stamp indicating the end of the interval \n",
    "\n",
    "    Returns: \n",
    "        float: a float representing attempt correct rate\n",
    "        \n",
    "    \"\"\" \n",
    "\n",
    "    # input check \n",
    "    assert(students == None or len(students) > 0) \n",
    "    assert(startTime == None or endTime == None or endTime > startTime) \n",
    "\n",
    "    # only get rows with desired students and start/end time \n",
    "    filteredDF = tutorLogDF.copy()\n",
    "    if(students != None): filteredDF = tutorLogDF.loc[tutorLogDF[\"Anon Student Id\"].isin(students)] \n",
    "    if(startTime != None): filteredDF = filteredDF.loc[filteredDF[\"timestamp\"] >= startTime]\n",
    "    if(endTime != None): filteredDF = filteredDF.loc[filteredDF[\"timestamp\"] <= endTime] \n",
    "\n",
    "    # total number of attempt = number of correct attempt + number of incorrect + number of hints requested \n",
    "    totalCorrect = filteredDF[\"Outcome\"].value_counts().get(\"CORRECT\", 0)\n",
    "    totalIncorrect = filteredDF[\"Outcome\"].value_counts().get(\"INCORRECT\", 0)\n",
    "    totalHint = filteredDF[\"Outcome\"].value_counts().get(\"HINT\", 0)\n",
    "    totalAttempts = totalCorrect + totalIncorrect + totalHint\n",
    "\n",
    "    # Tried some validation. However, the number of ATTEMPS values in the \n",
    "    # `Student Response Type` column does not match with CORRECT and INCORRECT\n",
    "    # outcomes, so the total number of attempts will be the sum of the two\n",
    "\n",
    "    # if(totalAttempts == 0): return 0\n",
    "    if(totalAttempts == 0): return np.nan\n",
    "    else: return totalCorrect / totalAttempts\n",
    "\n",
    "\n",
    "def getNumOfProblemsSolved(tutorLogDF, students=None, startTime=None, endTime=None): \n",
    "    \"\"\"Generate descriptive stats of the total number of problems solved by given students during given time interval \n",
    "\n",
    "    Args:\n",
    "        tutorLogDF (pd.Dataframe): tutor log dataframe imported from a datashop exported file \n",
    "        students (Iterable): one/several anon_stud_id's to get the performance percentage \n",
    "        startTime (_int_): unix time stamp indicating the start of the interval \n",
    "        endTime (_int_): unix time stamp indicating the end of the interval \n",
    "\n",
    "    Returns:\n",
    "        int: total number of problems solved by given students during given time interval \n",
    "    \"\"\"    \n",
    "\n",
    "    # do some filtering with students and start/end timestamp \n",
    "    filteredDF = filterWithStudents(tutorLogDF, students) \n",
    "    filteredDF = filterWithTime(filteredDF, startTime, endTime) \n",
    "\n",
    "    # Each problem should correspond to one and only one `done ButtonPressed`, \n",
    "    # so we can use the \"done ButtonPressed\" values in the `Step Name` column to \n",
    "    # extract the number of problems solved with these students between this \n",
    "    # time interval\n",
    "    numOfProblemsSolved = filteredDF[\"Step Name\"].value_counts().get(\"done ButtonPressed\", 0)\n",
    "\n",
    "    return numOfProblemsSolved\n",
    "\n",
    "def getNumOfHints(tutorLogDF, students=None, startTime=None, endTime=None): \n",
    "    \"\"\"Generate descriptive stats of the total number of hints requested by given students during given time interval \n",
    "\n",
    "    Args:\n",
    "        tutorLogDF (pd.Dataframe): tutor log dataframe imported from a datashop exported file \n",
    "        students (Iterable): one/several anon_stud_id's to get the performance percentage \n",
    "        startTime (_int_): unix time stamp indicating the start of the interval \n",
    "        endTime (_int_): unix time stamp indicating the end of the interval \n",
    "\n",
    "    Returns:\n",
    "        int: total number of hints requested by given students during given time interval \n",
    "    \"\"\"  \n",
    "\n",
    "    # do some filtering with students and start/end timestamp \n",
    "    filteredDF = filterWithStudents(tutorLogDF, students) \n",
    "    filteredDF = filterWithTime(filteredDF, startTime, endTime) \n",
    "\n",
    "    numOfHints = filteredDF[\"Student Response Type\"].value_counts().get(\"HINT_REQUEST\", 0)\n",
    "\n",
    "    return numOfHints\n",
    "\n",
    "\n",
    "def getAveNumOfHintsPerProblem(tutorLogDF, students=None, startTime=None, endTime=None): \n",
    "    \"\"\"Generates average number of hints used by given students in given time period \n",
    "\n",
    "    Args:\n",
    "        tutorLogDF (pd.Dataframe): tutor log dataframe imported from a datashop exported file \n",
    "        students (Iterable): one/several anon_stud_id's to get the performance percentage \n",
    "        startTime (_int_): unix time stamp indicating the start of the interval \n",
    "        endTime (_int_): unix time stamp indicating the end of the interval \n",
    "\n",
    "    Returns:\n",
    "        float: average number of hints used by given students in given time period\n",
    "    \"\"\"  \n",
    "\n",
    "    numOfHints = getNumOfHints(tutorLogDF, students=students, startTime=startTime, endTime=endTime) \n",
    "    numOfProblems = getNumOfProblemsSolved(tutorLogDF, students=students, startTime=startTime, endTime=endTime) \n",
    "    assert numOfProblems != 0, \"there is no problem solved with given conditions\" \n",
    "\n",
    "    return numOfHints / numOfProblems \n",
    "\n",
    "def getTimeToSolveSummary(tutorLogDF, students=None, startTime=None, endTime=None): \n",
    "    \"\"\" \n",
    "    Get the mean and std the time, in seconds, to solve each problem for \n",
    "    given student in given time interval\n",
    "\n",
    "    Args:\n",
    "        tutorLogDF (pd.Dataframe): tutor log dataframe imported from a datashop exported file \n",
    "        students (Iterable): one/several anon_stud_id's to get the performance percentage \n",
    "        startTime (_int_): unix time stamp indicating the start of the interval \n",
    "        endTime (_int_): unix time stamp indicating the end of the interval \n",
    "\n",
    "    Returns:\n",
    "        (float, float): mean and std of time taken to solve the problems (unit is second)\n",
    "    \"\"\"    \n",
    "\n",
    "    timeTakenForOneProblemUpperBound = 60*20 # in second \n",
    "\n",
    "    # basic filtering \n",
    "    filteredDF = filterWithStudents(tutorLogDF, students) \n",
    "    filteredDF = filterWithTime(filteredDF, startTime, endTime) \n",
    "\n",
    "    # rows with \"done ButtonPressed\" as value of `Step Name` should indicate the \n",
    "    # last transaction of the problem \n",
    "    filteredDF = filteredDF.loc[filteredDF[\"Step Name\"] == \"done ButtonPressed\"] \n",
    "    # the difference in time between the \"done ButtonPressed\" transaction and \n",
    "    # the `Problem Start Time` value should be time taken to solve the problem\n",
    "    timeTaken = filteredDF[\"Time\"].apply(UTCDatetime2epoch) - filteredDF[\"Problem Start Time\"].apply(UTCDatetime2epoch) \n",
    "    timeTaken = timeTaken.loc[timeTaken < timeTakenForOneProblemUpperBound]\n",
    "\n",
    "    return np.mean(timeTaken), np.std(timeTaken) \n",
    "\n",
    "def getKCLevelPerformance(tutorLogDF, students=None, startTime=None, endTime=None): \n",
    "    \"\"\"Generate the performance of given students in given time interval in each KC levels \n",
    "\n",
    "    Args:\n",
    "        tutorLogDF (pd.Dataframe): tutor log dataframe imported from a datashop exported file \n",
    "        students (Iterable): one/several anon_stud_id's to get the performance percentage \n",
    "        startTime (_int_): unix time stamp indicating the start of the interval \n",
    "        endTime (_int_): unix time stamp indicating the end of the interval \n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary mapping from KC's (string) to its correct rate (float)\n",
    "    \"\"\"    \n",
    "\n",
    "    # basic filtering \n",
    "    filteredDF = filterWithStudents(tutorLogDF, students) \n",
    "    filteredDF = filterWithTime(filteredDF, startTime, endTime) \n",
    "\n",
    "    # all KC levels are here: \n",
    "    KCLevels = ['cancel-const', 'division-simple', 'divide',\n",
    "                'subtraction-const', 'combine-like-const', 'subtraction-var',\n",
    "                'combine-like-var', 'cancel-var', 'distribute-division',\n",
    "                'division-complex'] \n",
    "    kc2CorrectRateMapping = dict() # to be returned \n",
    "\n",
    "    for kc in KCLevels: \n",
    "        kcDF = filteredDF.loc[filteredDF[\"KC (Default)\"] == kc] # dataframe with this KC only \n",
    "        correctRate = getStudentPerformanceSummary(kcDF) # calculate correct rate with this KC\n",
    "        kc2CorrectRateMapping[kc + \"_rate\"] = correctRate # populate the mapping dictionary\n",
    "    \n",
    "    return kc2CorrectRateMapping\n",
    "\n",
    "\n",
    "def getProblemLevelSummary(tutorLogDF, students=None, startTime=None, endTime=None): \n",
    "\n",
    "    # basic filtering \n",
    "    filteredDF = filterWithStudents(tutorLogDF, students) \n",
    "    filteredDF = filterWithTime(filteredDF, startTime, endTime) \n",
    "\n",
    "    # get the last transaction for each problem since it is unique \n",
    "    filteredDF = filteredDF.loc[filteredDF[\"Step Name\"] == \"done ButtonPressed\"] \n",
    "\n",
    "    # return problem level mean and std \n",
    "    return np.mean(filteredDF[\"Level (Position)\"]), np.std(filteredDF[\"Level (Position)\"])\n",
    "\n",
    "\n",
    "def getNumOfSteps(tutorLogDF, students=None, startTime=None, endTime=None):\n",
    "\n",
    "    # basic filtering \n",
    "    filteredDF = filterWithStudents(tutorLogDF, students) \n",
    "    filteredDF = filterWithTime(filteredDF, startTime, endTime) \n",
    "    # total number of not-NaN values in `Step Name` column is the number of steps\n",
    "    numOfSteps = filteredDF[\"Step Name\"].notnull().sum()\n",
    "\n",
    "    return numOfSteps\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# data-loading \n",
    "if __name__ ==\"__main__\": \n",
    "    tutorLogDF = pd.read_csv(\"raw data/tutor_log.tsv\", delimiter=\"\\t\", index_col=False) \n",
    "    tutorLogDF[\"Time Zone\"] = \"UTC\" # the logs are entered in UTC time zone \n",
    "    tutorLogDF[\"timestamp\"] = tutorLogDF[\"Time\"].apply(UTCDatetime2epoch) # add a new column with unix time stamps \n",
    "    tutorLogDF[\"EDT_time\"] = tutorLogDF[\"timestamp\"].apply(epoch2datetimeInEDT) # append a new column with EDT time information to be more intuitive \n",
    "\n",
    "    # only aceepting data within the experiment period, which is between 05/23/2022 and 05/25/2022 \n",
    "    experimentStartTimestamp = EDTDatetime2epoch(\"2022-05-23 08:00:00\")\n",
    "    experimentEndTimestamp = EDTDatetime2epoch(\"2022-05-25 16:00:00\")\n",
    "    tutorLogDF = filterWithTime(tutorLogDF, experimentStartTimestamp, experimentEndTimestamp) \n",
    "    # tutorLogDF.hist(column=\"timestamp\", bins=50) # validate by graph  \n",
    "\n",
    "def getAnnotatedTutorLogDF():\n",
    "    tutorLogDF = pd.read_csv(\"raw data/tutor_log.tsv\", delimiter=\"\\t\", index_col=False) \n",
    "    tutorLogDF[\"Time Zone\"] = \"UTC\" # the logs are entered in UTC time zone \n",
    "    tutorLogDF[\"timestamp\"] = tutorLogDF[\"Time\"].apply(UTCDatetime2epoch) # add a new column with unix time stamps \n",
    "    tutorLogDF[\"EDT_time\"] = tutorLogDF[\"timestamp\"].apply(epoch2datetimeInEDT) # append a new column with EDT time information to be more intuitive \n",
    "\n",
    "    # only aceepting data within the experiment period, which is between 05/23/2022 and 05/25/2022 \n",
    "    experimentStartTimestamp = EDTDatetime2epoch(\"2022-05-23 08:00:00\")\n",
    "    experimentEndTimestamp = EDTDatetime2epoch(\"2022-05-25 16:00:00\")\n",
    "    tutorLogDF = filterWithTime(tutorLogDF, experimentStartTimestamp, experimentEndTimestamp) \n",
    "\n",
    "    return tutorLogDF\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/jk/t2z3d3zd447g4wlv0rvml1400000gn/T/ipykernel_56615/1388600548.py:3: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tutorLogDF = pd.read_csv(\"raw data/tutor_log.tsv\", delimiter=\"\\t\", index_col=False)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# data summary chunk \n",
    "if __name__ == \"__main__\": \n",
    "    print(\"Below are some besic specs:\")\n",
    "    print(\"Correct and incorrect attempt proportions are\", getStudentPerformanceSummary(tutorLogDF))\n",
    "    print(\"Total number of problems solved in the three days:\", getNumOfProblemsSolved(tutorLogDF)) \n",
    "    print(\"Total number of hints requested in the three days\", getNumOfHints(tutorLogDF)) \n",
    "    print(\"Average number of hints per question for all students in the three days:\", getAveNumOfHintsPerProblem(tutorLogDF))\n",
    "    print(\"Mean and STD of time taken to solve the problems are:\", getTimeToSolveSummary(tutorLogDF)) \n",
    "    print(\"KC level performance summary:\")\n",
    "    print(getKCLevelPerformance(tutorLogDF))\n",
    "    print(\"Problem level summary:\", getProblemLevelSummary(tutorLogDF))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Below are some besic specs:\n",
      "Correct and incorrect attempt proportions are 0.8012281100750511\n",
      "Total number of problems solved in the three days: 2799\n",
      "Total number of hints requested in the three days 4043\n",
      "Average number of hints per question for all students in the three days: 1.4444444444444444\n",
      "Mean and STD of time taken to solve the problems are: (92.36132952108649, 100.60584470353174)\n",
      "KC level performance summary:\n",
      "{'cancel-const_rate': 0.9585714285714285, 'division-simple_rate': 0.5222551928783383, 'divide_rate': 0.9910198845413727, 'subtraction-const_rate': 0.3211091234347048, 'combine-like-const_rate': 0.7168949771689498, 'subtraction-var_rate': 0.37844611528822053, 'combine-like-var_rate': 0.6990291262135923, 'cancel-var_rate': 0.9671412924424972, 'distribute-division_rate': 0.23809523809523808, 'division-complex_rate': 0.3684210526315789}\n",
      "Problem level summary: (4.159699892818864, 2.9110680701431177)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# summary by days and periods \n",
    "\n",
    "# start and end time of each day/period \n",
    "               # period1                                  period2                                   period3                                   period4                                   period5\n",
    "startTimes =  [ \n",
    "              [EDTDatetime2epoch(\"2022-05-23 08:26:00\"), EDTDatetime2epoch(\"2022-05-23 10:13:00\"), EDTDatetime2epoch(\"2022-05-23 11:05:00\"), EDTDatetime2epoch(\"2022-05-23 12:36:00\"), EDTDatetime2epoch(\"2022-05-23 14:17:00\")], # day1\n",
    "              [EDTDatetime2epoch(\"2022-05-24 08:21:00\"), EDTDatetime2epoch(\"2022-05-24 10:02:00\"), EDTDatetime2epoch(\"2022-05-24 10:57:00\"), EDTDatetime2epoch(\"2022-05-24 12:24:00\"), EDTDatetime2epoch(\"2022-05-24 14:07:00\")], # day2\n",
    "              [EDTDatetime2epoch(\"2022-05-25 08:21:00\"), EDTDatetime2epoch(\"2022-05-25 10:01:00\"), EDTDatetime2epoch(\"2022-05-25 10:55:00\"), EDTDatetime2epoch(\"2022-05-25 12:24:00\"), EDTDatetime2epoch(\"2022-05-25 14:07:00\")]  # day3\n",
    "              ] \n",
    "\n",
    "               # period1                                  period2                                   period3                                   period4                                   period5\n",
    "endTimes =  [ \n",
    "            [EDTDatetime2epoch(\"2022-05-23 08:53:00\"), EDTDatetime2epoch(\"2022-05-23 10:41:00\"), EDTDatetime2epoch(\"2022-05-23 11:30:00\"), EDTDatetime2epoch(\"2022-05-23 13:00:00\"), EDTDatetime2epoch(\"2022-05-23 14:40:00\")], # day1\n",
    "            [EDTDatetime2epoch(\"2022-05-24 08:43:00\"), EDTDatetime2epoch(\"2022-05-24 10:27:00\"), EDTDatetime2epoch(\"2022-05-24 11:15:00\"), EDTDatetime2epoch(\"2022-05-24 12:48:00\"), EDTDatetime2epoch(\"2022-05-24 14:30:00\")], # day2\n",
    "            [EDTDatetime2epoch(\"2022-05-25 08:43:00\"), EDTDatetime2epoch(\"2022-05-25 10:24:00\"), EDTDatetime2epoch(\"2022-05-25 11:18:00\"), EDTDatetime2epoch(\"2022-05-25 12:47:00\"), EDTDatetime2epoch(\"2022-05-25 14:30:00\")]  # day3\n",
    "            ] \n",
    "\n",
    "def getPeriodsStartEndTimes(): \n",
    "    return startTimes, endTimes \n",
    "\n",
    "summaryDF = pd.DataFrame(columns=[\"dayID\", \"periodID\", \"correct_attempt_rate\", \"total_n_problems\", \"total_n_hints\", \n",
    "                                  \"ave_n_hint\", \"time_per_problem_mean\", \"time_per_problem_sd\", \n",
    "                                  \"problem_level_mean\", \"problem_level_std\",\n",
    "                                  'cancel-const_rate', 'division-simple_rate', 'divide_rate', \n",
    "                                  'subtraction-const_rate', 'combine-like-const_rate', \n",
    "                                  'subtraction-var_rate', 'combine-like-var_rate', 'cancel-var_rate', \n",
    "                                  'distribute-division_rate', 'division-complex_rate'])\n",
    "\n",
    "# column names of the KC level performance \n",
    "kc_rate_strings = ['cancel-const_rate', 'division-simple_rate', 'divide_rate', \n",
    "                   'subtraction-const_rate', 'combine-like-const_rate', \n",
    "                   'subtraction-var_rate', 'combine-like-var_rate', 'cancel-var_rate', \n",
    "                   'distribute-division_rate', 'division-complex_rate']\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "\n",
    "    days = 3\n",
    "    periods = 5\n",
    "    for day in range(days): \n",
    "        for period in range(periods): \n",
    "            # start and end time of the given day/period \n",
    "            startTime = startTimes[day][period] \n",
    "            endTime = endTimes[day][period] \n",
    "            filteredDF = filterWithTime(tutorLogDF, startTime, endTime) # get data in given time interval \n",
    "\n",
    "            # create a new row with populated values \n",
    "            newRowDict = {\"correct_attempt_rate\": [getStudentPerformanceSummary(filteredDF)], \n",
    "                          \"total_n_problems\": [getNumOfProblemsSolved(filteredDF)], \n",
    "                          \"total_n_hints\": [getNumOfHints(filteredDF)], \n",
    "                          \"ave_n_hint\": [getAveNumOfHintsPerProblem(filteredDF)], \n",
    "                          \"time_per_problem_mean\": [getTimeToSolveSummary(filteredDF)[0]], \n",
    "                          \"time_per_problem_sd\": [getTimeToSolveSummary(filteredDF)[1]],\n",
    "                          \"problem_level_mean\": [getProblemLevelSummary(filteredDF)[0]], \n",
    "                          \"problem_level_std\": [getProblemLevelSummary(filteredDF)[1]],\n",
    "                          \"dayID\": [day+1], \n",
    "                          \"periodID\": [period+1]\n",
    "                         } \n",
    "\n",
    "            kc_results = getKCLevelPerformance(filteredDF) # get performance stats in KC level, this is a dictionary \n",
    "            # populate the KC level performance columns \n",
    "            for kc_rate_string in kc_rate_strings: \n",
    "                newRowDict[kc_rate_string] = [kc_results[kc_rate_string]]\n",
    "\n",
    "            newDF = pd.DataFrame(newRowDict) \n",
    "            summaryDF = pd.concat([summaryDF, newDF], ignore_index=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# write the summary data file \n",
    "if __name__ == \"__main\": \n",
    "    summaryDF.to_csv(\"output_files/tutor_summary.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}